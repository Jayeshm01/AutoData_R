heritage_parsed = htmlParse("https://en.wikipedia.org/wiki/List_of_World_Heritage_in_Danger", encoding = "UTF-8")
tables = readHTMLTable(heritage_parsed, stringsAsFactors = FALSE)
#heritage_parsed = htmlParse("worldheritagedanger.html",encoding="UTF-8")
#tables = readHTMLTable(heritage_parsed, stringsAsFactors = FALSE)
danger_table = readHTMLTable(heritage_parsed, stringsAsFactors = FALSE)
danger_table = tables[[2]]
names(danger_table)
heritage_parsed = htmlParse("worldheritagedanger.html",encoding="UTF-8")
tables = readHTMLTable(heritage_parsed, stringsAsFactors = FALSE)
danger_table = readHTMLTable(heritage_parsed, stringsAsFactors = FALSE)
danger_table = tables[[2]]
names(danger_table)
# HTML
url = "http://www.r-datacollection.com/materials/html/fortunes.html"
fortunes = readLines(con = url)
#Parsing the Code using htmlParse
library(XML)
parsed_fortunes = htmlParse(file = url)
print(parsed_fortunes)
#Using a handler function for discarding the <body> node and its children
h1 = list("body" = function(x){NULL})
parsed_fortunes = htmlTreeParse(url, handlers = h1, asTree = TRUE)
parsed_fortunes$children
#Using generic handlers for DOM manipulation
h2 = list(
startElement = function(node, ...){
name = xmlName(node)
if(name %in% c("div", "title")){NULL}else{node}
},
comment = function(node){NULL}
)
parsed_fortunes = htmlTreeParse(file = url, handlers = h2, asTree = TRUE)
parsed_fortunes$children
#Specifying a function for generating handlers for the i nodes
getItalics = function() {
i_container = character()
list(i = function(node, ...){
i_container <= c(i_container, xmlValue(node))
},
returnI = function() i_container)
}
#Instantiating an instance of the handler
h3 = getItalics()
#Executing the parsing with the instatiated handler and printing the returned data
invisible(htmlTreeParse(url, handlers = h3))
h3$returnI()
parsed_fortunes$children
h1 = list("body" = function(x)*)
h1 = list("body" = function(x),list())
h1 = list("body" = function(x)*)
h1 = list("body" = function(x))
h1 = list("body" = function(x){NULL})
parsed_fortunes = htmlTreeParse(url, handlers = h1, asTree = TRUE)
parsed_fortunes$children
#XML
library(XML)
packageVersion("XML")
ls("package:XML")
lsf.str("package:XML")
parsed_stocks <- xmlParse(file = "stocks/technology.xml")
parsed_stocks <- xmlParse(file = "stocks/technology.xml")
#XML
library(XML)
parsed_stocks <- xmlParse(file = "stocks/technology.xml")
# validate XML
stocks <- xmlParse(file = "stocks/technology.xml", validate = TRUE)
stocks <- xmlParse(file = "stocks/technology-manip.xml", validate = TRUE)
# import and parse XML file
bond <- xmlParse("bond.xml")
class(bond)
#XML
library(XML)
parsed_stocks = xmlParse(file = "stocks/technology.xml")
setwd("G:/AutomatedData_R")
parsed_stocks = xmlParse(file = "stocks/technology.xml")
lsf.str("package:XML")
parsed_stocks = xmlParse(file = "stocks/technology.xml")
parsed_stocks = xmlParse(file = "stocks/technology.xml")
# validate XML
stocks = xmlParse(file = "stocks/technology.xml", validate = TRUE)
stocks = xmlParse(file = "stocks/technology-manip.xml", validate = TRUE)
# import and parse XML file
bond = xmlParse("bond.xml")
class(bond)
bond
bond
(root = xmlRoot(bond))
xmlName(root)
xmlSize(root)
root[[1]]
root[[1]][[1]]
root[["movie"]]
root["movie"]
root[["movie"]][[1]][[1]]
xmlParse("rsscode.rss")
xmlValue(root)
xmlValue(root[[1]])
xmlAttrs(root[[1]])
xmlGetAttr(root[[1]], "id")
xmlSApply(root, xmlValue)
xmlSApply(root[[1]], xmlValue)
xmlSApply(root, xmlAttrs)
xmlSApply(root, xmlGetAttr, "id")
(movie.df = xmlToDataFrame(root))
(movie.list = xmlToList(bond))
branchFun = function(){
container_close = numeric()
container_date = numeric()
Apple = function(node,...) {
date = xmlValue(xmlChildren(node)[[c("date")]])
container_date <= c(container_date, date)
close = xmlValue(xmlChildren(node)[[c("close")]])
container_close <= c(container_close, close)
print(c(close, date));Sys.sleep(0.5)
}
getContainer = function() data.frame(date=container_date, close=container_close)
list(Apple=Apple, getStore=getContainer)
}
(h5 = branchFun())
invisible(xmlEventParse(file = "stocks/technology.xml", branches = h5, handlers = list()))
library(RJSONIO)
library(stringr)
library(plyr)
install.packages('RJSONIO')
library(RJSONIO)
library(stringr)
library(plyr)
packageVersion("RJSONIO")
ls("package:RJSONIO")
lsf.str("package:RJSONIO")
isValidJSON("indy.json")
indy <- fromJSON("indy.json")
class(indy)
names(indy)
indy
indy[[1]]
indy[[1]][[1]]
sapply(indy[[1]], '[[', "name")
sapply(indy[[1]], '[[', "actors")
sapply(indy[[1]], '[[', "year")
# step-by-step approach 2
library(stringr)
library(stringr)
indy.vec <- unlist(indy, recursive = TRUE, use.names = TRUE)
indy.vec[str_detect(names(indy.vec), "name")]
indy.unlist <- sapply(indy[[1]], unlist)
indy.df <- do.call("rbind.fill", lapply(lapply(indy.unlist, t), data.frame, stringsAsFactors = FALSE))
names(indy.df)
peanuts.json <- fromJSON('peanuts.json', nullValue=NA, simplify = FALSE)
peanuts.df <- do.call("rbind", lapply(peanuts.json, data.frame, stringsAsFactors = FALSE))
peanuts.df
peanuts.out.json <- toJSON(peanuts.df, pretty = TRUE)
file.output <- file("peanuts_out.json")
writeLines(peanuts.out.json, file.output)
close(file.output)
detach("package:RJSONIO", unload=TRUE)
library(jsonlite)
packageVersion("jsonlite")
ls("package:jsonlite")
lsf.str("package:jsonlite")
x <- '[1, 2, true, false]' # numeric
fromJSON(x)
x <- '["foo", true, false]' # character
fromJSON(x)
x <- '[TRUE, true, false]' # logical
fromJSON(x)
x <- '[foo, true, false]'
fromJSON(x)
x <- '[true, false, null, null]'
fromJSON(x)
x <- '["foo", null]'
fromJSON(x)
x <- '[true, false, null]'
fromJSON(x)
x <- '[1, "foo", null, false]'
fromJSON(x)
x <- '[true, false, true, ]'
fromJSON(x)
x <- '{"foo":[1,2]}'
fromJSON(x)
x <- '{"foo":1}'
fromJSON(x)
(peanuts.json <- fromJSON('peanuts.json'))
(indy <- fromJSON("indy.json"))
indy.df <- indy$`indy movies`
indy.df$name
setwd("G:/AutomatedData_R")
library(XML)
parsed_doc <- htmlParse(file = "fortunes/fortunes.html")
print(parsed_doc)
xpathSApply(doc = parsed_doc, path = "/html/body/div/p/i")
xpathSApply(parsed_doc, "//body//p/i")
xpathSApply(parsed_doc, "//p/i")
xpathSApply(parsed_doc, "/html/body/div/*/i")
xpathSApply(parsed_doc, "//title/..")
xpathSApply(parsed_doc, "//address | //title")
twoQueries <- c(address = "//address", title = "//title")
xpathSApply(parsed_doc, twoQueries)
xpathSApply(parsed_doc, "//a/ancestor::div")
xpathSApply(parsed_doc, "//a/ancestor::div//i")
xpathSApply(parsed_doc, "//p/preceding-sibling::h1")
xpathSApply(parsed_doc, "//title/parent::*")
lowerCaseFun <- function(x) {
x <- tolower(xmlValue(x))
return(x)
}
xpathSApply(parsed_doc, "//div//i", fun = lowerCaseFun)
dateFun <- function(x) {
require(stringr)
date <- xmlGetAttr(node = x, name = "date")
year <- str_extract(date, "[0-9]{4}")
return(year)
}
xpathSApply(parsed_doc, "//div", dateFun)
parsed_stocks <- xmlParse(file = "technology/technology.xml")
companies <- c("Apple", "IBM", "Google")
(expQuery <- sprintf("//%s/close", companies))
getClose <- function(node) {
value <- xmlValue(node)
company <- xmlName(xmlParent(node))
mat <- c(company = company, value = value)
return(mat)
}
as.data.frame(t(xpathSApply(parsed_stocks, expQuery, getClose))
head(stocks, 3)
### XML namespaces
### --------------------------------------------------------------
parsed_xml <- xmlParse("titles.xml")
parsed_xml <- xmlParse("titles.xml")
parsed_xml
xpathSApply(parsed_xml, "//title", fun = xmlValue)
xpathSApply(parsed_xml, "//*[local-name()='title']", xmlValue)
xpathSApply(parsed_xml, "//x:title", namespaces = c(x = "http://funnybooknames.com/crockford"), fun = xmlValue)
xpathSApply(parsed_xml, "//x:title", namespaces = c(x = "http://www.w3.org/1999/xhtml"), fun = xmlValue)
nsDefs <- xmlNamespaceDefinitions(parsed_xml)[[2]]
ns <- nsDefs$uri
ns
xpathSApply(parsed_xml, "//x:title", naemspaces = c(x = ns), xmlValue)
as.data.frame(t(xpathSApply(parsed_stocks, expQuery, getClose))
head(stocks, 3)
parsed_xml <- xmlParse("titles.xml")
parsed_xml
xpathSApply(parsed_xml, "//title", fun = xmlValue)
xpathSApply(parsed_xml, "//*[local-name()='title']", xmlValue)
xpathSApply(parsed_xml, "//x:title", namespaces = c(x = "http://funnybooknames.com/crockford"), fun = xmlValue)
xpathSApply(parsed_xml, "//x:title", namespaces = c(x = "http://www.w3.org/1999/xhtml"), fun = xmlValue)
nsDefs <- xmlNamespaceDefinitions(parsed_xml)[[2]]
ns <- nsDefs$uri
ns
xpathSApply(parsed_xml, "//x:title", naemspaces = c(x = ns), xmlValue)
head(stocks, 3)
as.data.frame(t(xpathSApply(parsed_stocks, expQuery, getClose))
head(stocks, 3)
parsed_xml <- xmlParse("titles.xml")
as.data.frame(t(xpathSApply(parsed_stocks, expQuery, getClose))
head(stocks, 3)
parsed_xml <- xmlParse("titles.xml")
parsed_xml
xpathSApply(parsed_xml, "//title", fun = xmlValue)
xpathSApply(parsed_xml, "//*[local-name()='title']", xmlValue)
xpathSApply(parsed_xml, "//x:title", namespaces = c(x = "http://funnybooknames.com/crockford"), fun = xmlValue)
parsed_doc <- htmlParse(file = "fortunes/fortunes.html")
print(parsed_doc)
xpathSApply(doc = parsed_doc, path = "/html/body/div/p/i")
xpathSApply(parsed_doc, "//body//p/i")
xpathSApply(parsed_doc, "//p/i")
xpathSApply(parsed_doc, "/html/body/div/*/i")
xpathSApply(parsed_doc, "//title/..")
xpathSApply(parsed_doc, "//address | //title")
twoQueries <- c(address = "//address", title = "//title")
xpathSApply(parsed_doc, twoQueries)
xpathSApply(parsed_doc, "//a/ancestor::div")
xpathSApply(parsed_doc, "//a/ancestor::div//i")
xpathSApply(parsed_doc, "//p/preceding-sibling::h1")
xpathSApply(parsed_doc, "//title/parent::*")
xpathSApply(parsed_doc, "//div/p[position()=1]")
xpathSApply(parsed_doc, "//div/p[last()]")
xpathSApply(parsed_doc, "//div/p[last()-1]")
xpathSApply(parsed_doc, "//div[count(.//a)>0]")
xpathSApply(parsed_doc, "//div[count(./@*)>2]")
xpathSApply(parsed_doc, "//*[string-length(text())>50]")
xpathSApply(parsed_doc, "//div[not(count(./@*)>2)]")
xpathSApply(parsed_doc, "//div[@date='October/2011']")
xpathSApply(parsed_doc, "//*[contains(text(), 'magic')]")
xpathSApply(parsed_doc, "//div[starts-with(./@id, 'R')]")
xpathSApply(parsed_doc, "//div[substring-after(./@date, '/')='2003']//i")
xpathSApply(parsed_doc, "//title", fun = xmlValue)
xpathSApply(parsed_doc, "//div", xmlAttrs)
xpathSApply(parsed_doc, "//div", xmlGetAttr, "lang")
lowerCaseFun <- function(x) {
x <- tolower(xmlValue(x))
return(x)
}
xpathSApply(parsed_doc, "//div//i", fun = lowerCaseFun)
dateFun <- function(x) {
require(stringr)
date <- xmlGetAttr(node = x, name = "date")
year <- str_extract(date, "[0-9]{4}")
return(year)
}
xpathSApply(parsed_doc, "//div", dateFun)
idFun <- function(x) {
id <- xmlGetAttr(x, "id")
id <- ifelse(is.null(id), "not specified", id)
return(id)
}
xpathSApply(parsed_doc, "//div", idFun)
parsed_stocks <- xmlParse(file = "technology/technology.xml")
companies <- c("Apple", "IBM", "Google")
(expQuery <- sprintf("//%s/close", companies))
getClose <- function(node) {
value <- xmlValue(node)
company <- xmlName(xmlParent(node))
mat <- c(company = company, value = value)
return(mat)
}
as.data.frame(t(xpathSApply(parsed_stocks, expQuery, getClose))
head(stocks, 3)
parsed_xml <- xmlParse("titles.xml")
parsed_xml
as.data.frame(t(xpathSApply(parsed_stocks, expQuery, getClose))
stocks$value <- as.numeric(as.character(stocks$value))
head(stocks, 3)
parsed_xml <- xmlParse("titles.xml")
parsed_xml
xpathSApply(parsed_xml, "//title", fun = xmlValue)
xpathSApply(parsed_xml, "//*[local-name()='title']", xmlValue)
xpathSApply(parsed_xml, "//x:title", namespaces = c(x = "http://funnybooknames.com/crockford"), fun = xmlValue)
xpathSApply(parsed_xml, "//x:title", namespaces = c(x = "http://www.w3.org/1999/xhtml"), fun = xmlValue)
nsDefs <- xmlNamespaceDefinitions(parsed_xml)[[2]]
ns <- nsDefs$uri
ns
xpathSApply(parsed_xml, "//x:title", naemspaces = c(x = ns), xmlValue)
as.data.frame(t(xpathSApply(parsed_stocks, expQuery, getClose))
head(stocks, 3)
### XML namespaces
### --------------------------------------------------------------
parsed_xml <- xmlParse("titles.xml")
parsed_xml
xpathSApply(parsed_xml, "//title", fun = xmlValue)
xpathSApply(parsed_xml, "//*[local-name()='title']", xmlValue)
xpathSApply(parsed_xml, "//x:title", namespaces = c(x = "http://funnybooknames.com/crockford"), fun = xmlValue)
library(RCurl)
library(httr)
library(stringr)
install.packages('RCurl')
#install.packages('RCurl')
install.packages('httr')
#install.packages('RCurl')
#install.packages('httr')
library(RCurl)
library(httr)
library(stringr)
packageVersion("RCurl")
ls("package:RCurl")
lsf.str("package:RCurl")
t <- "I'm Eddie! How are you & you? 1 + 1 = 2"
(url <- URLencode(t, reserve = TRUE))
URLdecode(url)
cat(getURL("http://httpbin.org/headers",
useragent = str_c(R.version$platform,
R.version$version.string,
sep=", ")))
cat(getURL("http://httpbin.org/headers", referer = "http://www.r-datacollection.com/"))
cat(getURL("http://httpbin.org/headers", cookie = "id=12345;domain=httpbin.org"))
(secret <- base64("This is a secret message"))
base64Decode(secret)
cat(getURL("http://httpbin.org/headers", proxy = "109.205.54.112:8080", followlocation = TRUE)) # this is a fictional proxy IP address and will not work
curlVersion()$protocols
names(getCurlOptionsConstants())
cat(getURL("http://www.r-datacollection.com/materials/http/helloworld.html"))
pngfile <- getBinaryURL("http://www.r-datacollection.com/materials/http/sky.png")
writeBin(pngfile, "sky.png")
url <- "http://www.r-datacollection.com/materials/http/GETexample.php"
namepar <- "Eddie"
agepar <- "32"
url_get <- str_c(url, "?", "name=", namepar, "&", "age=", agepar)
cat(getURL(url_get))
url <- "http://www.r-datacollection.com/materials/http/POSTexample.php"
cat(postForm(url, name = "Eddie", age = 32, style="post"))
url <- "r-datacollection.com/materials/http/helloworld.html"
res <- getURL(url = url, customrequest = "HEAD", header = TRUE)
cat(str_split(res,"\r")[[1]])
url <- "www.r-datacollection.com/materials/http/helloworld.html"
(pres <- curlPerform(url = url))
pres <- NULL
performOptions <- curlOptions(url = url, writefunc = function(con) pres <<- con)
curlPerform(.opts = performOptions)
pres
content <- basicTextGatherer()
header <- basicTextGatherer()
debug <- debugGatherer()
performOptions <- curlOptions(url = url, writefunc = content$update,
headerfunc = header$update, debugfunc = debug$update, verbose = T)
curlPerform(.opts=performOptions)
str_sub(content$value(), 1, 100)
header$value()
names(debug$value())
debug$value()["headerOut"]
handle <- getCurlHandle()
handle <- getCurlHandle(useragent = str_c(R.version$platform,
R.version$version.string,
sep=", "),
httpheader = c(from = "ed@datacollection.com"),
followlocation = TRUE,
cookiefile = "")
urls <- sprintf("http://www.r-datacollection.com/materials/http/abunchofasciis/file00%d.html", 330:340)
lapply(urls, getURL, curl = handle)
url <- "www.r-datacollection.com/materials/http/helloworld.html"
res <- getURL(url = url, header = TRUE)
cat(str_split(res, "\r")[[1]])
handle <- getCurlHandle(customrequest = "HEAD")
res <- getURL(url = url, curl = handle, header = TRUE)
cat(str_split(res, "\r")[[1]])
handle2 <- dupCurlHandle(handle,
httpheader = c(from = "ed@datacollection.com"))
curl_options <- curlOptions(header = TRUE, customrequest = "HEAD")
res <- getURL(url = url, .opts = curl_options)
cat(postForm(url, .params = c(name = "Eddie", age = "32"),
style = "post",
.opts = list(useragent = "Eddie's R scraper",
referer = "www.r-datacollection.com")))
options(RCurlOptions = list(header = TRUE, customrequest = "HEAD"))
res <- getURL(url = url)
options(RCurlOptions = list())
res <- getURL("www.r-datacollection.com/materials/http/POSTexample.php",
customrequest = "POST",
postfields = "name=Eddie&age=32")
cat(str_split(res, "\r")[[1]])
url <- "r-datacollection.com/materials/http/ReturnHTTP.php"
res <- getURL(url = url)
cat(str_split(res, "\r")[[1]])
standardHeader <- list(
from        = "eddie@r-datacollection.com",
'user-agent' = str_c(R.version$platform,
R.version$version.string,
sep=", "))
res <- getURL(url = url, httpheader = standardHeader)
cat(str_split(res, "\r")[[1]])
defaultOptions <-  curlOptions(
httpheader = list(
from = "Eddie@r-datacollection.com",
'user-agent'   = str_c(R.version$platform,
R.version$version.string,
sep=", ")),
followlocation = TRUE,
maxredirs      = 10,
connecttimeout = 10,
timeout        = 300,
cookiefile     = "RCurlCookies.txt",
cainfo = system.file("CurlSSL","cacert.pem", package = "RCurl"))
options(RCurlOptions = defaultOptions)
options(RCurlOptions = list())
getURL("http://www.stata-datacollection.com")
url <- "httpbin.org/get"
res <- getURL(url = url)
cat(res)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
debugInfo <- debugGatherer()
names(debugInfo)
class(debugInfo[[1]])
url <- "r-datacollection.com/materials/http/helloworld.html"
res <- getURL(url = url,
debugfunction = debugInfo$update,
verbose = T)
names(debugInfo$value())
cat(debugInfo$value()["text"])
cat(str_split(debugInfo$value()["headerIn"], "\r")[[1]])
cat(str_split(debugInfo$value()["headerOut"], "\r")[[1]])
cat(str_split(debugInfo$value()["dataIn"], "\r")[[1]])
cat(str_split(debugInfo$value()["dataOut"], "\r")[[1]])
cat(str_split(debugInfo$value()["sslDataIn"], "\r")[[1]])
cat(str_split(debugInfo$value()["sslDataOut"], "\r")[[1]])
handle <- getCurlHandle()
url <- "r-datacollection.com/materials/http/helloworld.html"
res <- getURL(url = url, curl = handle)
handleInfo <- getCurlInfo(handle)
names(handleInfo)
handleInfo[c("total.time", "pretransfer.time")]
preTransTimeNoReuse   <- rep(NA, 10)
preTransTimeReuse <- rep(NA, 10)
url <- "r-datacollection.com/materials/http/helloworld.html"
for(i in 1:10){
handle <- getCurlHandle()
res <- getURL(url=url, curl=handle)
handleInfo             <- getCurlInfo(handle)
preTransTimeNoReuse[i] <- handleInfo$pretransfer.time
}
handle <- getCurlHandle()
for(i in 1:10){
res <- getURL(url=url, curl=handle)
handleInfo           <- getCurlInfo(handle)
preTransTimeReuse[i] <- handleInfo$pretransfer.time
}
preTransTimeNoReuse
preTransTimeReuse
getCurlErrorClassNames()[c(2:4,7,8,10,23,29,35,64)]
url1 <- "wwww.r-datacollection.com/materials/http/helloworld.html"
res <- getURL(url1)
url2 <-  "www.r-datacollection.com/materials/http/helloworld.html"
res <- tryCatch(
getURL(url = url1),
COULDNT_RESOLVE_HOST = function(error){
getURL(url = url2)
},
error = function(error){
print(error$message)
NA
}
)
cat(str_split(res,"\r")[[1]])
